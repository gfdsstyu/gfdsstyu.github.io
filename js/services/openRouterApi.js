/**
 * Groq API ì„œë¹„ìŠ¤
 * ì´ˆê³ ì† LLM ì¶”ë¡  (Llama, Qwen, Kimi ë“±)
 */

/**
 * Groq Chat Session í´ë˜ìŠ¤
 */
export class OpenRouterChatSession {
  constructor(apiKey, model = 'llama-3.3-70b-versatile', systemInstruction = null, generationConfig = {}) {
    this.apiKey = apiKey;
    this.modelName = model;
    this.systemInstruction = systemInstruction;
    this.generationConfig = {
      temperature: 0.7,
      max_tokens: 8192, // Groq API ìµœëŒ€ê°’: 8192
      ...generationConfig
    };
    this.history = [];
    this.initialized = false;
  }

  /**
   * ì„¸ì…˜ ì´ˆê¸°í™”
   */
  async initialize() {
    if (this.initialized) return;

    // ì‹œìŠ¤í…œ ë©”ì‹œì§€ ì¶”ê°€
    if (this.systemInstruction) {
      this.history = [{
        role: 'system',
        content: this.systemInstruction
      }];
    }

    this.initialized = true;
    console.log('âœ… [Groq] ì„¸ì…˜ ì´ˆê¸°í™” ì™„ë£Œ:', this.modelName);
  }

  /**
   * ë©”ì‹œì§€ ì „ì†¡ - ìë™ ì¬ì‹œë„ í¬í•¨
   * @param {string} message - ì‚¬ìš©ì ë©”ì‹œì§€
   * @param {number} maxRetries - ìµœëŒ€ ì¬ì‹œë„ íšŸìˆ˜ (ê¸°ë³¸: 3)
   * @returns {Promise<string>} - AI ì‘ë‹µ
   */
  async sendMessage(message, maxRetries = 3) {
    if (!this.initialized) {
      await this.initialize();
    }

    let lastError = null;

    for (let attempt = 1; attempt <= maxRetries; attempt++) {
      try {
        console.log(`ğŸ“¤ [Groq] ë©”ì‹œì§€ ì „ì†¡ ì¤‘... (ì‹œë„ ${attempt}/${maxRetries})`);

        // ì‚¬ìš©ì ë©”ì‹œì§€ íˆìŠ¤í† ë¦¬ì— ì¶”ê°€
        this.history.push({
          role: 'user',
          content: message
        });

        // Groq TPM ì œí•œ ëŒ€ì‘: ìµœê·¼ ëŒ€í™”ë§Œ ìœ ì§€ (system + ìµœê·¼ 1ê°œ ëŒ€í™” ìŒ)
        // Exam AI TutorëŠ” ê° ì§ˆë¬¸ì´ ë…ë¦½ì ì´ë¯€ë¡œ ì´ì „ ëŒ€í™” ì»¨í…ìŠ¤íŠ¸ê°€ ê±°ì˜ í•„ìš” ì—†ìŒ
        const maxHistoryPairs = 1; // user-assistant ìŒ ìµœëŒ€ ê°œìˆ˜ (í˜„ì¬ ì§ˆë¬¸ë§Œ)
        let messagesToSend = [];

        // System ë©”ì‹œì§€ëŠ” í•­ìƒ í¬í•¨
        const systemMessages = this.history.filter(m => m.role === 'system');
        const conversationMessages = this.history.filter(m => m.role !== 'system');

        // ìµœê·¼ Nê°œ ëŒ€í™”ë§Œ ìœ ì§€ (user-assistant ìŒ ê¸°ì¤€)
        const recentMessages = conversationMessages.slice(-maxHistoryPairs * 2);
        messagesToSend = [...systemMessages, ...recentMessages];

        console.log(`ğŸ” [Groq] ì „ì†¡ ë©”ì‹œì§€ ìˆ˜: ${messagesToSend.length} (ì „ì²´: ${this.history.length})`);

        // Groq API í˜¸ì¶œ
        const response = await fetch('https://api.groq.com/openai/v1/chat/completions', {
          method: 'POST',
          headers: {
            'Content-Type': 'application/json',
            'Authorization': `Bearer ${this.apiKey}`
          },
          body: JSON.stringify({
            model: this.modelName,
            messages: messagesToSend,
            temperature: this.generationConfig.temperature,
            max_tokens: this.generationConfig.max_tokens
          })
        });

        if (!response.ok) {
          const errorData = await response.json().catch(() => ({}));
          throw new Error(`Groq API Error: ${response.status} - ${errorData.error?.message || response.statusText}`);
        }

        const data = await response.json();
        const assistantMessage = data.choices[0].message.content;

        // ì‘ë‹µ íˆìŠ¤í† ë¦¬ì— ì¶”ê°€
        this.history.push({
          role: 'assistant',
          content: assistantMessage
        });

        console.log('âœ… [Groq] ì‘ë‹µ ë°›ìŒ:', assistantMessage.substring(0, 100) + '...');
        return assistantMessage;

      } catch (error) {
        lastError = error;
        const errorMessage = error.message || String(error);

        // 429 Rate Limit ì—ëŸ¬ ì²˜ë¦¬
        if (errorMessage.includes('429') || errorMessage.includes('Rate limit')) {
          // Rate limit ì—ëŸ¬ ë©”ì‹œì§€ì—ì„œ ëŒ€ê¸° ì‹œê°„ ì¶”ì¶œ (ì˜ˆ: "Please try again in 20.13s")
          const waitMatch = errorMessage.match(/try again in ([\d.]+)s/);
          const waitSeconds = waitMatch ? Math.ceil(parseFloat(waitMatch[1])) : 30;

          console.warn(`â³ [Groq] Rate Limit ë„ë‹¬ - ${waitSeconds}ì´ˆ ëŒ€ê¸° í•„ìš”`);

          // ì‚¬ìš©ì ì¹œí™”ì ì¸ ì—ëŸ¬ ë©”ì‹œì§€ë¡œ ë³€ê²½
          throw new Error(
            `Groq API ì‚¬ìš©ëŸ‰ í•œë„ ì´ˆê³¼ì…ë‹ˆë‹¤.\n` +
            `${waitSeconds}ì´ˆ í›„ì— ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.\n\n` +
            `ğŸ’¡ íŒ: ë” ì ì€ í† í°ì„ ì‚¬ìš©í•˜ëŠ” ëª¨ë¸(llama-3.1-8b-instant)ì„ ì„ íƒí•˜ê±°ë‚˜, ` +
            `Gemini ëª¨ë¸ë¡œ ë³€ê²½í•´ë³´ì„¸ìš”.`
          );
        }

        // 500 ì—ëŸ¬ ë˜ëŠ” ì¼ì‹œì  ì˜¤ë¥˜ì¸ ê²½ìš°ì—ë§Œ ì¬ì‹œë„
        const isRetryable = errorMessage.includes('500') ||
                           errorMessage.includes('502') ||
                           errorMessage.includes('503') ||
                           errorMessage.includes('timeout') ||
                           errorMessage.includes('network');

        if (!isRetryable) {
          console.error('âŒ [Groq] ì¬ì‹œë„ ë¶ˆê°€ëŠ¥í•œ ì˜¤ë¥˜:', error);
          throw error;
        }

        if (attempt < maxRetries) {
          // ì§€ìˆ˜ ë°±ì˜¤í”„: 1ì´ˆ, 2ì´ˆ, 4ì´ˆ...
          const waitTime = Math.min(1000 * Math.pow(2, attempt - 1), 5000);
          console.warn(`âš ï¸ [Groq] ì˜¤ë¥˜ ë°œìƒ, ${waitTime}ms í›„ ì¬ì‹œë„... (${attempt}/${maxRetries})`, errorMessage);
          await new Promise(resolve => setTimeout(resolve, waitTime));
        } else {
          console.error(`âŒ [Groq] ìµœëŒ€ ì¬ì‹œë„ íšŸìˆ˜ ì´ˆê³¼ (${maxRetries}íšŒ)`, error);
        }
      }
    }

    throw lastError;
  }

  /**
   * ëŒ€í™” ì´ë ¥ ê°€ì ¸ì˜¤ê¸°
   */
  async getHistory() {
    return this.history
      .filter(msg => msg.role !== 'system')
      .map(msg => ({
        role: msg.role === 'assistant' ? 'assistant' : 'user',
        content: msg.content
      }));
  }

  /**
   * ëŒ€í™” ì´ë ¥ ì´ˆê¸°í™”
   */
  async clearHistory() {
    // ì‹œìŠ¤í…œ ë©”ì‹œì§€ë§Œ ìœ ì§€
    this.history = this.systemInstruction ? [{
      role: 'system',
      content: this.systemInstruction
    }] : [];
    console.log('ğŸ—‘ï¸ [Groq] ëŒ€í™” ì´ë ¥ ì´ˆê¸°í™”ë¨');
  }
}

/**
 * Groq ì§€ì› ëª¨ë¸ ëª©ë¡ (2025ë…„ 12ì›” ê³µì‹ ë¬¸ì„œ ê¸°ì¤€)
 * https://console.groq.com/docs/models
 */
export const GROQ_MODELS = {
  // Production Models - Llama
  'llama-3.3-70b-versatile': {
    name: 'Llama 3.3 70B Versatile',
    icon: 'ğŸ¦™',
    provider: 'Meta'
  },
  'llama-3.1-8b-instant': {
    name: 'Llama 3.1 8B Instant',
    icon: 'ğŸ¦™',
    provider: 'Meta'
  },

  // Preview Models - Llama 4
  'meta-llama/llama-4-maverick-17b-128e-instruct': {
    name: 'Llama 4 Maverick 17B',
    icon: 'ğŸ¦™',
    provider: 'Meta'
  },
  'meta-llama/llama-4-scout-17b-16e-instruct': {
    name: 'Llama 4 Scout 17B',
    icon: 'ğŸ¦™',
    provider: 'Meta'
  },

  // Preview Models - Qwen
  'qwen/qwen3-32b': {
    name: 'Qwen 3 32B',
    icon: 'ğŸ¯',
    provider: 'Qwen'
  },

  // Preview Models - Moonshot
  'moonshotai/kimi-k2-instruct': {
    name: 'Kimi K2 Instruct',
    icon: 'ğŸŒ™',
    provider: 'Moonshot'
  },
  'moonshotai/kimi-k2-instruct-0905': {
    name: 'Kimi K2 Instruct (0905)',
    icon: 'ğŸŒ™',
    provider: 'Moonshot'
  },

  // Featured Models - OpenAI
  'openai/gpt-oss-120b': {
    name: 'GPT OSS 120B',
    icon: 'ğŸ¤–',
    provider: 'OpenAI'
  }
};
